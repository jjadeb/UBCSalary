---
project:
  type: website
  output-dir: docs
title: "UBC Salaries: Exploratory Analysis of Gender"
author: "Jade Bouchard"
format: 
    html: 
        toc: true
        toc-depth: 2
    pdf: 
        toc: true
        toc-depth: 2
bibliography: references.bib
execute: 
    echo: false
    warning: false
editor: source
---

```{python}
import pandas as pd
import pickle
from IPython.display import Markdown, display
from tabulate import tabulate
from os import listdir
import re
```


## Aim

This document explores The University of British Columbia (UBC) faculty salaries based on guessed gender.

## Data

Salary data for UBC staff members making over 75000 CAD anually was sourced from @salary_data. To access individual financial reports, click on the yearly links under the header `Statement of Financial Information (SOFI)`.

Gender data was inferred using first names of staff members. In order to guess gender, I used baby name datasets [@canadian_babyname; @american_babyname; @indian_babyname].

## Ethics

In this project first names are used to guess whether someone is "male" or "female". Many people do not fit into these categories. Misgendering, or incorrectly assigning gender to individuals, can have harmful effects. In addition, while first names can sometimes be an indication of someones gender, first names are not inherintly gendered. 

I encourage anyone who notices a misgendering within this project to raise an issue in the issues tab, and it will be corrected. In addition, I encourage respectful and inclusive language in all discussions related to gender. 

## Methods

The Python programming language [@Python] was used to perform this analysis.

### Data collection

As mentioned earlier, for UBC salary data, I used the salary PDFs that UBC releases every year [@salary_data]. The following steps were taken to collect the data.

- Use the `requests` package to access the UBC Financial Reports [webpage](https://finance.ubc.ca/reporting-planning-analysis/reports-and-disclosures).
- Extract all links and filter for the Statement of Financial Information (SOFI) PDF links which contain salary information.
- If there are any PDFs from which I have not already collected salary data, extract the text from the PDF using the package `pypdf`.
- Store the new salary data

An exerpt of the raw salary data is below.

```{python}
  with open("../data/salary_data/raw_salary_data.pickle", "rb") as raw_salary_dict:
        raw_salary_text_data = pickle.load(raw_salary_dict)

print(raw_salary_text_data["2020"][200210:200300])
```


### Data cleaning

In this section, the following steps are taken to clean the salary data:

For each year of salary data,

- Remove special charachters from text. For example, ÅŸ.
- Remove unnecessary text content. For example, the "[Auditor's] Qualified Opinion".
- Uses regex to process the raw text data into a structured DataFrame with columns: `Name`, `Remuneration`, `Expenses`.
- Split the `Name` column into first and last names. 
- Convert salary (remuneration) and expenses columns to a numeric data type.
- Shorten first and last names to allow for easier name matching between years. For example, someone's name in 2020 could be "Bob M Sherbert" and in 2021 their name could be "Bob-M Sherbert". This name would be shortened to Bob Sherbert to avoid mismatching.

Then, I concatenate dataframes from all years together.

@tbl-cleandata shows an expert of the cleaned salary data.
```{python}
#| label: tbl-cleandata
#| tbl-cap: Clean UBC Salary Data
clean_salary_data = pd.read_csv("../data/salary_data/clean_salary_data/all_clean_salary_data.csv")
clean_salary_data.head()
```

## Gender Prediction 

### Babyname Corpus
In order to predict gender, I used datasets with babynames and assigned genders. In order to have a somewhat diverse set of baby names, I used babynames from Canadian, American, and Indian sources [@canadian_babyname, @american_babyname, @indian_babyname].

For each UBC staff name, I found whether that name was more common among girls or boys in the babyname corpus. Then, I guessed the gender that was most common.

In @tbl-babynames, the `Estimated_Accuracy` column shows the percentage of gender majority from the babyname corpus. For example, if 95% of babys named George in the dataset were male, the `Estimated_Accuracy` column value would be 0.95. Any staff names that had less than an 80% gender majority were given a null gender.

```{python}
#| label: tbl-babynames
#| tbl-cap: Babyname Data
clean_babynames = pd.read_csv("../data/gender_corpus/clean_name_corpus.csv")
low_accuracy_df = clean_babynames.sort_values(by="Estimated_Accuracy").head(1)
low_accuracy_name = low_accuracy_df.iloc[0]["First_Name"]
low_accuracy_value = low_accuracy_df.iloc[0]["Estimated_Accuracy"]
low_accuracy_df
```

@tbl-babynames shows the name `{python} low_accuracy_name` has about the same number of boy and girl names. This name has an accuracy of `{python} low_accuracy_value`. So, since its not above the 80% threshold, anyone with that name would have a gender value of `None` assigned.

```{python}
corpus_predictions = pd.read_csv("../data/gender_predictions/corpus_gender_predictions.csv")
non_corpus_data = pd.read_csv("../data/gender_predictions/needs_gender_predictions.csv")
matched_percentage = round(100*corpus_predictions.shape[0]/(corpus_predictions.shape[0] + non_corpus_data.shape[0]),2)
```

@tbl-corpuspreds shows some of the predictions made on UBC staff members using the babyname corpus.
```{python}
#| label: tbl-corpuspreds
#| tbl-cap: Babyname Data
corpus_predictions = pd.read_csv("../data/gender_predictions/corpus_gender_predictions.csv")
corpus_predictions_accurate = corpus_predictions[corpus_predictions["Estimated_Accuracy"] >= 0.8]
corpus_predictions_accurate[["First_Name","Guessed_Gender","Estimated_Accuracy"]].head(5)
```

```{python}
corpus_predictions = pd.read_csv("../data/gender_predictions/corpus_gender_predictions.csv")
corpus_predictions_accurate = corpus_predictions[corpus_predictions["Estimated_Accuracy"] >= 0.8]
corpus_accurate_value = round(corpus_predictions_accurate.shape[0]*100/corpus_predictions.shape[0],1)
```

Around `{python} matched_percentage`% of UBC staff names were matched with names in the babyname corpus. `{python} corpus_accurate_value`% of the corpus matches had over 0.8 accuracy and were kept, the rest were given a prediction of `None`.

### NLTK

For UBC staff names that were not found in the babyname corpus, I used a natural language processing model to predict genders [@NLTK]. 

@tbl-needspreds shows some examples of names not found in the babyname corpus.

```{python}
#| label: tbl-needspreds
#| tbl-cap: Example Staff Names Not Found in Babyname Datasets
nltk_predictions_needed = pd.read_csv("../data/gender_predictions/needs_gender_predictions.csv")
pd.DataFrame(nltk_predictions_needed.head(5)["First_Name"])
```


In order to train and evaluate the model, the babyname corpus was split into a trianing and test set.

Features used to train the Naive Bayes model were the last 2, 3, and 4 letters of the staff member's first name. 

```{python}
 with open("../data/gender_predictions/accuracy.txt", "r") as file:
    accuracy = float(file.read())
```

 The accuracy on the test set was `{python} accuracy`. However, the accuracy on the UBC staff names that were missing from the babyname corpus is very likely lower than `{python} accuracy`. This is due to the fact that the data we are making predictions on is quite different from our training data.

 Below are the top three features the classifier found most useful for making correct predictions.

```{python}
 with open("../models/gender_classifier.pickle", "rb") as model_file:
    classifier = pickle.load(model_file)
    classifier.show_most_informative_features(n=3)
```

We can see there are patterns in first names that could be helpful for predicting gender. However, these patterns may not show up often in the unique UBC staff that were not in the babyname datasets.

Finally, after making predictions on the UBC staff data, we can see in @tbl-worstnltkpreds the predictions our classifier was least confident about, and in @tbl-bestnltkpreds and the predictions it was most confident about. 

```{python}
#| label: tbl-worstnltkpreds
#| tbl-cap: Least Confident NLTK predictions
nltk_predictions = pd.read_csv("../data/gender_predictions/nltk_gender_predictions.csv")
nltk_predictions.sort_values(by="Estimated_Accuracy", ascending=True)[["First_Name", "Guessed_Gender","Estimated_Accuracy"]].drop_duplicates().head(5)
```

```{python}
#| label: tbl-bestnltkpreds
#| tbl-cap: Most Confident NLTK predictions
nltk_predictions = pd.read_csv("../data/gender_predictions/nltk_gender_predictions.csv")
nltk_predictions.sort_values(by="Estimated_Accuracy", ascending=False)[["First_Name", "Guessed_Gender","Estimated_Accuracy"]].drop_duplicates().head(5)
```

To represent the extra uncertainty in using a classifier compared to the babyname corpus, the `Estimated_Accuracy` column for NLTK predictions is the classifier's predict-proba score multplied by `{python} accuracy`. Where `{python} accuracy` is the accuracy of the classifier on the test set.

Like with the babyname corpus predictions, NLTK predictions with an accuracy less than 0.8 were given a gender prediction of `None`. This was the case if the predict-proba score from the classifier was less than `{python} round(0.8/accuracy,2)`.

```{python}
nltk_predictions = pd.read_csv("../data/gender_predictions/nltk_gender_predictions.csv")
accurate_nltk_predictions = nltk_predictions[nltk_predictions['Estimated_Accuracy'] >= 0.8]
nltk_kept_preds = round(100*accurate_nltk_predictions.shape[0]/(nltk_predictions.shape[0]),1)
```

Overall, `{python} nltk_kept_preds`% of the NLTK predictions were kept and the rest were given a prediction of `None`.

## Exploratory Data Analysis

Using gender predictions, I created a variety of plots showing the salaries of staff members of UBC. This data only includes staff members making over 75000 CAD anually.

```{python}
## Find plots of the most recent year
# Get bar plot files
files = listdir("../plots/bar_plots")
# Create regex pattern for files of interest
year_pattern = re.compile(r'top_ten_salaries_(20[0-9][0-9])\.png')
# Find regex match for files of interest
matches = list(map(lambda x: year_pattern.search(x), files))
# Find the year listed for each file
years = list(map(lambda x: int(x.group(1)) if x else 0, matches))
# Find the most recent year available
most_recent_year = max(years)
```

```{python}
# Get plot file paths
bar_plot_path = f"../plots/bar_plots/top_ten_salaries_{most_recent_year}.png"
boxplot_path = f"../plots/box_plots/boxplot_of_salary_by_gender_{most_recent_year}.png"
histogram_path = f"../plots/histogram_plots/histogram_of_salaries_by_gender_{most_recent_year}.png"
```

![Top Ten Salaries](`{python} bar_plot_path`){#fig-bar}

@fig-bar shows the top ten UBC staff salaries.

![Salary Boxplot](`{python} boxplot_path`){#fig-box}

@fig-box shows box plots of UBC staff salaries.

![Salary Histogram](`{python} histogram_path`){#fig-hist}

@fig-hist shows a histogram plot of UBC staff salaries. This histogram is split by guessed gender.

![Salary Line Plot](../plots/line_plots/lineplot_of_median_salary_by_gender.png){#fig-line}

@fig-line shows a line plot of median UBC staff salaries over all the years I have collected data. There seems to be fairly minimal change in median salary between 2020 and 2023, and then an increase in median salary in 2024. Males have a higher median salary for years 2020 to 2024.

![Salary Change Line Plot](../plots/line_plots/lineplot_of_median_salary_percent_change_by_gender.png){#fig-linechange}

@fig-linechange shows a line plot of the median percent change in UBC staff salaries over all the years I have collected data. The data point at 2024 reflects the median percent change from FY23 to FY24. To calculate these values, first I calculated the percent change in salary for individaul staff members who had data for consecutive years. Then, for each year transition, I calculated the median percent change for guessed males and guessed females. 

There seems to be a slight decrease median raise percentage between 2020 and 2023, and then a large increase in in 2024. This is in line with our observations for @fig-line. Females have a slightly higher median percentage salary increase for years 2020 to 2024.

## Limitations

**Due to the low level of accuracy in gender predicion of this report, conlusions drawn are not meaningful.**

- NLTK training data not representative of real data
- no practical way to check ground truths
- data sources
- gender not binary
- Naive Bayes conditional independence assumption violated
  These features are correlated which violates the Naive Bayes conditional independence assumption. However, I decided to stick with the NLTK naive bayes classifier as it efficiently handles text data, large datasets, and still performs fairly well.
- Can see males have a larger median salary for years 2020 - 2024. Cannot infer any reason for this without further investigation.
- etc.

## References