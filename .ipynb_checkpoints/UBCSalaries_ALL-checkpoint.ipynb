{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049fcc89-134c-488e-9acf-583bf7955766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import openpyxl\n",
    "import pylab as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from wordcloud import WordCloud\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import io\n",
    "\n",
    "import requests\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5cb446-b907-42e8-8a3f-749a1ce4eee0",
   "metadata": {},
   "source": [
    "# UBC Salaries Across Gender, Department, and Job Title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a0c6aa-88b0-4d85-916f-d59090686d26",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f3db72-7201-4015-aa90-95e6ccdf71c2",
   "metadata": {},
   "source": [
    "The primary objective of this project is to develop skills in data wrangling, machine learning, and Tableau. A secondary goal is to create a Tableau dashboard for visualizing University of British Columbia (UBC) faculty salaries based on gender, department, and job title.\n",
    "\n",
    "To prioritize learning, rather than directly requesting salary data from UBC by department, job title, and gender, I will rely on the annual PDF of salary data released by UBC, along with information from UBC's faculty directory and global baby name datasets.\n",
    "\n",
    "The project involves several steps: gathering and cleaning salary data, collecting and cleaning department and job title data, making gender predictions for each faculty member, and ultimately visualizing the cleaned data through a Tableau dashboard.\n",
    "\n",
    "This approach incorporates tasks such as scraping, clustering, and data transformation, offering an in-depth exploration of data manipulation techniques and fostering a comprehensive understanding of the intricacies involved in data wrangling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a3cd0-baf1-4e02-b4a4-41a798e45539",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed88137d-7874-4851-a601-fbc34eaabb3d",
   "metadata": {},
   "source": [
    "The following list is how the rest of this project will unfold:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08c2c07-8b91-45dc-894a-0cca5667271e",
   "metadata": {},
   "source": [
    "- Data Collection and Cleaning\n",
    "    - Salary Data\n",
    "    - Department and Job Title Data\n",
    "- Gender Prediction\n",
    "- Data Visualization\n",
    "- Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea6507-2207-4cf0-8442-7cc9019ebb5e",
   "metadata": {},
   "source": [
    "## Data Collection and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2b235-9221-4f0a-9ffd-6b4260565e1b",
   "metadata": {},
   "source": [
    "### Salary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3b662-0a92-401a-b98c-c77e4cb60aac",
   "metadata": {},
   "source": [
    "We can use the PDF salary information that UBC releases every year. The salary information is retrieved from the following website: [UBC Financial Reports](https://finance.ubc.ca/reporting-planning-analysis/financial-reports). The first step is to go to this website and find the links for years with available salary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afa06f25-5c08-4f4e-9940-05661e28d237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2023': 'https://finance.ubc.ca/sites/finserv.ubc.ca/files/FY23%20UBC%20Statement%20of%20Financial%20Information.pdf',\n",
       " '2022': 'https://finance.ubc.ca/sites/finserv.ubc.ca/files/FY22%20UBC%20Statement%20of%20Financial%20Information.pdf',\n",
       " '2021': 'https://finance.ubc.ca/sites/finserv.ubc.ca/files/FY21%20UBC%20Statement%20of%20Financial%20Information.pdf',\n",
       " '2020': 'https://finance.ubc.ca/sites/finserv.ubc.ca/files/FY20_Financial_Information_Act_Report.pdf'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = {} # get all financial report links\n",
    "r = requests.get('https://finance.ubc.ca/reporting-planning-analysis/financial-reports') # go to financial report webpage\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "finance_section = soup.find('h3', string = re.compile('Financial Information Act')) # find the \"Financial Information Act\" header\n",
    "salary_link_elements = finance_section.find_next_sibling('ul').findAll('li') # find the section with the links\n",
    "for element in salary_link_elements: # collect all of the links\n",
    "    salary_link = element.find('a').get('href') # get link from element\n",
    "    year = \"20\" + re.search(\"FY([0-9][0-9])\", salary_link).group(1) # use regex to get the year in each link\n",
    "    links[year] = salary_link # add year and link to dictionary \n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ae55e-a201-41db-a152-9b38017898b6",
   "metadata": {},
   "source": [
    "Above we can see the years with available salary information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bddf7cf-5e4c-4c13-9207-631543583e20",
   "metadata": {},
   "source": [
    "Next, I will create a function that when given a link, will return the text from the link in string form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4defcb9b-71b0-46d5-8d47-43c05788184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_salary_data(link):\n",
    "    '''find UBC salary pdf for given year and return it in string form'''\n",
    "    url = link\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    f = io.BytesIO(r.content)\n",
    "    \n",
    "    all_text = \"\" # variable to store all text in pdf\n",
    "    reader = PdfReader(f)\n",
    "    contents = reader.pages # returns a list of pages\n",
    "    for content in contents: # for each page, extract text\n",
    "        all_text += content.extract_text() # add text to all_text\n",
    "        \n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dfc5dd-e6ab-4355-90da-7847ecad6454",
   "metadata": {},
   "source": [
    "Now, I will create a function that can take the salary data in string form, clean it up, and return a dataframe with the columns: `First Name`, `Last Name`, `Remuneration`, `Expenses`, and `Year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0385e91-86aa-47d5-8b8a-c88f125eb827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_salary_data(raw_data, year):\n",
    "    '''take salary data in string form and turn it into a dataframe, add a column and fill it with the given year'''\n",
    "    # Remove beginning/end text\n",
    "    raw_data_a = raw_data.split('Earnings greater than')[0].split('external cost recoveries.')[1]\n",
    "    raw_data_a\n",
    "    \n",
    "    # Remove unnessessary lines\n",
    "    raw_data_b = re.split('([\\.\\p{L},\\s-]+[\\s\\n]+[0-9,-]+[\\s\\n]+[0-9,-]+)', raw_data_a)\n",
    "    \n",
    "    raw_data_c = [i for i in raw_data_b if (',' in i) and ('SCHEDULE' not in i)]\n",
    "    \n",
    "    # Remove spaces and new lines\n",
    "    raw_data_d = [i.replace('\\n',' ').replace(\"  \",\" \").strip() for i in raw_data_c]\n",
    "    raw_data_d = [i.replace(\"  \",\" \") for i in raw_data_d]\n",
    "    \n",
    "    # # Split data into Names/Remuneration/Expenses\n",
    "    raw_data_e = [i.rsplit(' ',2) for i in raw_data_d]\n",
    "    raw_data_e\n",
    "    \n",
    "    # Create Column names\n",
    "    ubc_salary_data = pd.DataFrame(raw_data_e, columns = ['Name', 'Remuneration', 'Expenses'])\n",
    "    \n",
    "    # Split Name into First/Last Name\n",
    "    ubc_salary_data['First Name'] = ubc_salary_data['Name'].str.split(', ', expand = True)[1]\n",
    "    ubc_salary_data['Last Name'] = ubc_salary_data['Name'].str.split(', ', expand = True)[0]\n",
    "    \n",
    "    \n",
    "    # Select necessary columns\n",
    "    ubc_salary_data = ubc_salary_data[['Last Name','First Name','Remuneration','Expenses']]\n",
    "    \n",
    "    # turn salary column from string to numeric\n",
    "    ubc_salary_data['Remuneration'] = ubc_salary_data['Remuneration'].astype(str).str.replace(',','')\n",
    "    ubc_salary_data['Remuneration'] = pd.to_numeric(ubc_salary_data['Remuneration'], errors='coerce')\n",
    "\n",
    "    ubc_salary_data['Year'] = f\"{year}\"\n",
    "\n",
    "    return ubc_salary_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfefb7c6-b4f6-4185-8abb-f9f8fc285962",
   "metadata": {},
   "source": [
    "Now I will loop through the salary data links I collected, clean up the data for each year, and combine the data into one dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e065f3a9-3fc1-4be4-b551-9c82e3d47108",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = pd.DataFrame(columns = ['Last Name', 'First Name', 'Remuneration', 'Expenses','Year']) # create empty dataframe for salary data\n",
    "most_recent = True # keeps track of most recent salary data\n",
    "for year, link in links.items(): # for each year that UBC has data for\n",
    "    raw = fetch_salary_data(link) # get raw data in string form\n",
    "    salaries = clean_salary_data(raw, year) # get clean data as a dataframe\n",
    "    if most_recent: # export the most recent salary data so that we can collect the new department/job title info\n",
    "        salaries.to_csv(f\"/Users/jadebouchard/Desktop/UBC Salaries/Salary Data/{year}.csv\")\n",
    "        most_recent = False\n",
    "    if salary_data.empty: # avoid warning that we shouldn't be concatenating empty dataframes\n",
    "        salary_data = salaries\n",
    "    else:\n",
    "        salary_data = pd.concat([salary_data,salaries]) # paste dataframes together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2051abb3-5d0c-4ba3-a676-a11886e74f1c",
   "metadata": {},
   "source": [
    "Below you can see a recent and less recent section of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "498b7253-3111-4f00-accd-0e0d34769caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Remuneration</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aamodt</td>\n",
       "      <td>Tor</td>\n",
       "      <td>193153.0</td>\n",
       "      <td>5,597</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abanto Salguero</td>\n",
       "      <td>Arleni Karina</td>\n",
       "      <td>107723.0</td>\n",
       "      <td>393</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbassi</td>\n",
       "      <td>Arash</td>\n",
       "      <td>109136.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abdalkhani</td>\n",
       "      <td>Arman</td>\n",
       "      <td>101829.0</td>\n",
       "      <td>-</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abdi</td>\n",
       "      <td>Ali</td>\n",
       "      <td>238203.0</td>\n",
       "      <td>2,981</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Last Name     First Name  Remuneration Expenses  Year\n",
       "0           Aamodt            Tor      193153.0    5,597  2023\n",
       "1  Abanto Salguero  Arleni Karina      107723.0      393  2023\n",
       "2          Abbassi          Arash      109136.0       82  2023\n",
       "3       Abdalkhani          Arman      101829.0        -  2023\n",
       "4             Abdi            Ali      238203.0    2,981  2023"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4633cf0-9e2d-4f44-8ecd-d4f825ba6b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Remuneration</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>Zumbo</td>\n",
       "      <td>Bruno</td>\n",
       "      <td>294953.0</td>\n",
       "      <td>10,102</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>Zumpano</td>\n",
       "      <td>Franco</td>\n",
       "      <td>94463.0</td>\n",
       "      <td>420</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>Zumrawi</td>\n",
       "      <td>Abdel Azim</td>\n",
       "      <td>98145.0</td>\n",
       "      <td>-</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>Zwicker</td>\n",
       "      <td>Jill</td>\n",
       "      <td>145343.0</td>\n",
       "      <td>12,523</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>Zysk</td>\n",
       "      <td>Eva</td>\n",
       "      <td>93058.0</td>\n",
       "      <td>2,489</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Last Name  First Name  Remuneration Expenses  Year\n",
       "6219     Zumbo       Bruno      294953.0   10,102  2020\n",
       "6220   Zumpano      Franco       94463.0      420  2020\n",
       "6221   Zumrawi  Abdel Azim       98145.0        -  2020\n",
       "6222   Zwicker        Jill      145343.0   12,523  2020\n",
       "6223      Zysk         Eva       93058.0    2,489  2020"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6086edd1-6f81-42f0-ae22-4f5dacc95074",
   "metadata": {},
   "source": [
    "This scraping process missed about 70 entries due to formatting issues. These entries will be removed going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddb8e6c0-2542-4283-bd02-1e095dd7d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data = salary_data[~salary_data.isnull().any(axis = 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9b4f11-5dca-4337-8ff9-9a401e60fa2d",
   "metadata": {},
   "source": [
    "Also, now that the department and title data has been merged onto the salary data, to try and maintain consistency over the years names will be shortened. For example, \"A Bobby\" will be shortened to \"Bobby\" and \"Anne Michele\" will be shortened to \"Anne\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17a26963-575c-49a8-88d4-cfca211a3110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_name(name):\n",
    "    '''remove initials from names, and if two names just keep the first one'''\n",
    "    name = name.strip() # remove white space\n",
    "    name = name.replace(\" -\",\"-\").replace(\"- \",\"-\") # make sure names that should be connected are connected\n",
    "    if len(name.split(\" \")) <= 1: # if only one word, return word\n",
    "        return name\n",
    "    else:\n",
    "        words = name.split(\" \")\n",
    "        for word in words: # remove initials if they exist\n",
    "            if len(word) == 1:\n",
    "                words.remove(word)\n",
    "        return words[0] # return first word\n",
    "\n",
    "salary_data.loc[:,\"First Name\"] = salary_data[\"First Name\"].apply(shorten_name)\n",
    "salary_data.loc[:,\"Last Name\"] = salary_data[\"Last Name\"].apply(shorten_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541a1d26-5e28-444e-a3d3-c4b46436766c",
   "metadata": {},
   "source": [
    "Finally, I will add columns that show the salary difference in dollar amount and percentage compared to the previous year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19bb132d-b4b4-448e-bad0-a1363e241477",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data['Year'] = salary_data['Year'].apply(int) # change year column to integer\n",
    "salary_data['Last Year'] = salary_data['Year'] - 1 # find previous year for each row\n",
    "original_df = salary_data.copy() # create a new variable to represent salary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4123a83-c1ff-4c73-960a-498c265a516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a self-merge to get the salary information for the previous year\n",
    "salary_data = original_df.merge(original_df[['Last Name','First Name','Year','Remuneration']], how='left', left_on=['Last Name','First Name','Last Year'], right_on=['Last Name','First Name','Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c040732-01c1-4823-9395-15ac88a8d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns to represent salary increase/decrease in dollar amount and another column for percentage\n",
    "salary_data['Remuneration_Difference_Dollar'] = salary_data['Remuneration_x'] - salary_data['Remuneration_y']\n",
    "salary_data['Remuneration_Difference_Percent'] = round((salary_data['Remuneration_x'] - salary_data['Remuneration_y'])/salary_data['Remuneration_x']*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82a9989e-4f35-4587-b286-1704851862a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary columns\n",
    "salary_data = salary_data.drop(columns = ['Last Year', 'Year_y', 'Remuneration_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e1a95a-b564-4724-862b-fba3ff0dff4a",
   "metadata": {},
   "source": [
    "Now we have clean salary data for UBC staff members. I will export this data so that it is available for anyone to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7f1222d-4e2c-4f97-a1a5-b91e36ee5e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_data.to_excel('data/UBC_Salary_DF_All_Years.xlsx', index = False)\n",
    "salary_data.to_csv('data/UBC_Salary_DF_All_Years.csv', index = False, encoding = \"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fff90c-53c4-4e7a-8440-a0ffb492b742",
   "metadata": {},
   "source": [
    "### Department and Job Title Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56689548-cb3f-4a16-a4b7-13796e41e479",
   "metadata": {},
   "source": [
    "#### Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907553ac-d60f-44c5-96a2-57e74d183af2",
   "metadata": {},
   "source": [
    "After collecting the salary data, I retrieved department and job title information for each UBC staff member from the following [website](https://directory.ubc.ca/index.cfm). To gather the data I used Python's requests package. The code and entirety of the raw data will not be provided here because I'm not allowed to publicly distribute all of this data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee18eddd-29c8-4871-9252-433cbe3b810d",
   "metadata": {},
   "source": [
    "Below I will combine the department and job title I have gathered over the years, and merge it onto the salary dataset. An **important note** is that I don't have department or job title information for 2020, 2021, and 2022. For these years I'm going to fill them in with 2023 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c496214e-43da-4929-89a2-62a79fd65ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving 2023 data\n",
    "department_data = pd.read_excel(\"/Users/jadebouchard/Desktop/UBC Salaries/Department Data/UBC_Salary_Department_2023.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59c0279f-2d28-4e0f-8562-0c7e750df5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating department and job title info for 2020, 2021, and 2022 using 2023 data.\n",
    "for year in ['2020','2021','2022']:\n",
    "    department_data['Year'] = year\n",
    "    department_data.to_excel(f\"/Users/jadebouchard/Desktop/UBC Salaries/Department Data/UBC_Salary_Department_{year}.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa6422d7-b392-4de6-b676-d63b504254fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining job title and department data across all years\n",
    "\n",
    "# note: when I say department data, I mean department and job title data\n",
    "\n",
    "# path to scraped department data\n",
    "department_path = r'/Users/jadebouchard/Desktop/UBC Salaries/Department Data' \n",
    "\n",
    "# collect department data file paths for each year\n",
    "all_department_files = glob.glob(os.path.join(department_path, \"*.xlsx\"))\n",
    "\n",
    "# collect dataframes for each year of scraped department data\n",
    "department_dataframes = []\n",
    "\n",
    "for filename in all_department_files:\n",
    "    df = pd.read_excel(filename, index_col=None, header=0)\n",
    "    department_dataframes.append(df)\n",
    "\n",
    "# merge department dataframes together\n",
    "pop_df = pd.concat(department_dataframes, axis=0).drop_duplicates()[['Last Name',\"First Name\",\"Department\",\"Title\",\"Year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad24318d-9c6d-4a16-8e0d-ba8ab80b1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any duplicates and convert year to string\n",
    "pop_df = pd.concat(department_dataframes, axis=0).drop_duplicates()\n",
    "pop_df['Year'] = pop_df['Year'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5ea7e62-6c61-4bc0-bac9-2accbfa4abf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Remuneration</th>\n",
       "      <th>Expenses</th>\n",
       "      <th>Department</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aamodt</td>\n",
       "      <td>Tor</td>\n",
       "      <td>193153.0</td>\n",
       "      <td>5,597</td>\n",
       "      <td>Electrical and Computer Engineering</td>\n",
       "      <td>Professor</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abanto Salguero</td>\n",
       "      <td>Arleni Karina</td>\n",
       "      <td>107723.0</td>\n",
       "      <td>393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbassi</td>\n",
       "      <td>Arash</td>\n",
       "      <td>109136.0</td>\n",
       "      <td>82</td>\n",
       "      <td>Office of the Vice-President, Academic</td>\n",
       "      <td>Intern, Strategy and Decision Support</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abdalkhani</td>\n",
       "      <td>Arman</td>\n",
       "      <td>101829.0</td>\n",
       "      <td>-</td>\n",
       "      <td>Surgery, Faculty of Medicine - Vancouver Coast...</td>\n",
       "      <td>Clinical Instructor, Otolaryngology - Head and...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abdi</td>\n",
       "      <td>Ali</td>\n",
       "      <td>238203.0</td>\n",
       "      <td>2,981</td>\n",
       "      <td>Educational Studies (EDST)</td>\n",
       "      <td>Professor</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Last Name     First Name  Remuneration Expenses  \\\n",
       "0           Aamodt            Tor      193153.0    5,597   \n",
       "1  Abanto Salguero  Arleni Karina      107723.0      393   \n",
       "2          Abbassi          Arash      109136.0       82   \n",
       "3       Abdalkhani          Arman      101829.0        -   \n",
       "4             Abdi            Ali      238203.0    2,981   \n",
       "\n",
       "                                          Department  \\\n",
       "0                Electrical and Computer Engineering   \n",
       "1                                                NaN   \n",
       "2             Office of the Vice-President, Academic   \n",
       "3  Surgery, Faculty of Medicine - Vancouver Coast...   \n",
       "4                         Educational Studies (EDST)   \n",
       "\n",
       "                                               Title  Year  \n",
       "0                                          Professor  2020  \n",
       "1                                                NaN  2020  \n",
       "2              Intern, Strategy and Decision Support  2020  \n",
       "3  Clinical Instructor, Otolaryngology - Head and...  2020  \n",
       "4                                          Professor  2020  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop any index columns\n",
    "pop_df = pop_df[pop_df.columns.drop(list(pop_df.filter(regex='Unnamed')))]\n",
    "pop_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798284f5-7084-45c9-9d64-7e13b1f24dcf",
   "metadata": {},
   "source": [
    "We now have retrieved (or invented) job title and department data for 2020 onwards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04080f53-168f-45a6-9fc0-b1b9bda2ea47",
   "metadata": {},
   "source": [
    "Now, for some additional data clean-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "245a932a-6495-4eae-ae16-52a2a9ea8f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes a small number of observations that weren't formatted correctly\n",
    "pop_df = pop_df[~pop_df.isnull().any(axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4c0f5cd-7a33-4442-b90d-9ad11a136e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten names so that merge with salary data works\n",
    "pop_df.loc[:,\"First Name\"] = pop_df[\"First Name\"].apply(shorten_name)\n",
    "pop_df.loc[:,\"Last Name\"] = pop_df[\"Last Name\"].apply(shorten_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59018424-5276-46af-8ab3-d946e68c1878",
   "metadata": {},
   "source": [
    "The next step is to combine the department data with the salary data collected earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f61ed31c-e828-4e00-bd6a-f90fced0bb07",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/42/47ypm7jn1sl58j9cxg7tyxk80000gn/T/ipykernel_44451/4131720128.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Merging department info onto all salary data - all job titles/departments are from data collected in 2023\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpop_df_dep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalary_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"First Name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Last Name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Department'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Year\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"left\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"First Name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Last Name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Year\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         )\n\u001b[1;32m    168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m                         \u001b[0;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Year'"
     ]
    }
   ],
   "source": [
    "# Merging department info onto all salary data - all job titles/departments are from data collected in 2023\n",
    "pop_df_dep = pd.merge(salary_data, pop_df[[\"First Name\",\"Last Name\",'Department','Title',\"Year\"]], how = \"left\", on = [\"First Name\",\"Last Name\",\"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d2cbb4-4930-416b-8e62-a8f8168642c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824304c0-72ee-4d31-ba2a-b00cc9e749bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove people with the same first name and last name since I cannot tell them apart\n",
    "pop_df_dep = pop_df_dep.drop_duplicates(subset=['First Name','Last Name','Year'], keep = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c4f60-e336-4753-aae9-2a4525f2249c",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63813777-8f02-42af-8c23-9c197bfebb42",
   "metadata": {},
   "source": [
    "To make the data processing step work smoothly, I will convert the department and job title columns to a string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be9511b-6585-4bd5-98d2-19f5aa3d2d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep[\"Department\"] = pop_df_dep[\"Department\"].apply(str)\n",
    "pop_df_dep[\"Title\"] = pop_df_dep[\"Title\"].apply(str)\n",
    "pop_df_dep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f024c90-eff4-4cec-b169-a5fca0255388",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep['Department'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc31708-71f8-4462-8b9f-407cb9d90cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep['Title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78b1ad3-977d-4bf1-8741-261028a8b5d2",
   "metadata": {},
   "source": [
    "Now, I will correct any incorrect data that I am aware of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00de05e-83c6-4c82-8b28-4cfc2b9d59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# David Patrick was listed as a prof in the computer science faculty since there is someone with a similar name in that faculty. \n",
    "# based on the salary value this david patrick should be in the medicine faculty\n",
    "pop_df_dep.loc[(pop_df_dep['First Name'] == \"David\") & (pop_df_dep['Last Name'] == \"Patrick\"),'Department'] = \"Centre for Disease Control\"\n",
    "pop_df_dep.loc[(pop_df_dep['First Name'] == \"David\") & (pop_df_dep['Last Name'] == \"Patrick\"),'Title'] = \"Executive Medical Director and Deputy Provincial Health Officer Professor, School of Population and Public Health\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4659dec-ec35-4988-b290-492dae8ea6e0",
   "metadata": {},
   "source": [
    "Now, the department and title information is separated. However, there are so many unique values that it will make data analysis difficult and ineffective. Therefore, I will group together similar department data and title data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbe5ff-227a-4a43-8b6d-e00372113ff9",
   "metadata": {},
   "source": [
    "#### Grouping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939fa41b-a18a-473a-b1d9-ee40c17680c1",
   "metadata": {},
   "source": [
    "For clustering Department I used the DBScan clustering method. I chose this method over KMeans as it allows for points to not have an assigned Department. It also lets me avoid choosing the number of groups beforehand. I chose a fairly conservative eps value (0.25) as it's important that points don't get miss-classified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f581a618-fe85-43fd-85a2-e142bebfc692",
   "metadata": {},
   "source": [
    "The first step is to do some preprocessing. I will remove some words and symbols from the department column that I don't want the algorithm using to determine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a711aa8b-afc0-4f47-8e25-47900b0dc5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing some words and symbols from the department text as it confuses the cluster algorithm\n",
    "pop_df_dep[\"Department - short\"] = pop_df_dep[\"Department\"].replace({\"Faculty of \":\"\",\n",
    "                                                             \"Faculty\":\"\",\n",
    "                                                             \"IKBFoS\":\"\", \"IKBFASS\":\"\", \n",
    "                                                             \"â€“\":\"\", \"-\":\"\", \"Department\":\"\", \"School\":\"\",\n",
    "                                                             \"Office\":\"\",\"Institute\":\"\",\n",
    "                                                             f\"\\n\":\"\",\n",
    "                                                             'Centre':\"\"}, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce571030-2c87-43de-abe0-5b6bb2a8877a",
   "metadata": {},
   "source": [
    "I'm also choosing to remove Location info about university, although it would be interesting to look at salary disparity across location another time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31782d0f-3997-4e6a-a94a-9453b6b3c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep[\"Department - short\"] = pop_df_dep[\"Department - short\"].replace({\"UBC Okanagan\":\"\"}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0403eddc-21f0-4c14-bd74-8d9818115221",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep = pop_df_dep.reset_index(drop=True) # reset index so embedder works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a93ea-2e02-4328-bac1-242357d179b0",
   "metadata": {},
   "source": [
    "The next step is to train the clustering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25827aa-bfb1-4565-9aff-d21ef14b2fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"paraphrase-distilroberta-base-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352e357-55d5-42d8-8f04-6e280914b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_department = embedder.encode(pop_df_dep['Department - short'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9f3313-d639-482f-a387-75a4147891de",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_department_df = pd.DataFrame(emb_department, index=pop_df_dep.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb663ec2-7595-4ac6-814f-6fce333e6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relate min_samples to the amount of data collected in links\n",
    "dbscan = DBSCAN(eps=0.2, min_samples = 15*len(links),metric='cosine')\n",
    "dbscan.fit(emb_department_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b0ffa-dd01-44be-b637-6145d47830a9",
   "metadata": {},
   "source": [
    "Now that we have our model fitted, we can analyze its performance. To do this, I create and examine a silhouette plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f912d45-5a3f-4858-91d5-e8eaebb7d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = len(set(dbscan.labels_))\n",
    "dbscan.n_clusters = n_clusters\n",
    "dbscan.predict = lambda x: dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd2188-d511-4df2-b257-83ac7a1fc7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = SilhouetteVisualizer(dbscan, colors=\"yellowbrick\")\n",
    "visualizer.fit(emb_department)  \n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f2255-728b-454d-b766-6f51e0008746",
   "metadata": {},
   "source": [
    "From the above silhouette plot, I can see that that the chosen eps and min_sample values do a pretty good job of seperating the data into distinct clusters. \n",
    "\n",
    "One item of note is that the 1 cluster (data points with a null Department value) makes up about 35% of the data. This informs us that many observations do not have an associated department in the data, therefore conclusions based of the data may not accurately represent the entire population of UBC faculty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39578d3-8343-45e9-82c7-5b6a7aec3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(dbscan.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e5f093-deae-4947-b135-62b0baca9b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep[\"Department (General)\"] = dbscan.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302645a1-5dc7-4e82-9596-f835f8d17b53",
   "metadata": {},
   "source": [
    "The code above has assigned many labels to the observations. Each label is currently represented by a number which is not very interpretable. Below I will find the most common word(s) for each label and use that string to represent the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f614a8d4-2e80-4dc1-a534-ddf44021ce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep[\"Department (General)\"] = pop_df_dep[\"Department (General)\"].astype(str) # turn column to type string\n",
    "for cluster_num in range(-1,len(set(dbscan.labels_))-1): # for each label:\n",
    "    cluster = pop_df_dep[pop_df_dep[\"Department (General)\"] == str(cluster_num)] # filter data for label\n",
    "    name_string = ' '.join(cluster[\"Department - short\"].tolist()) # create long string of all words in label\n",
    "    if cluster_num == -1:\n",
    "            pop_df_dep.loc[pop_df_dep[\"Department (General)\"] == str(cluster_num), \"Department (General)\"] = np.nan\n",
    "    elif name_string.strip():\n",
    "        wordcloud = WordCloud().generate(name_string) # find the commonality of words\n",
    "        str_label = list((wordcloud.words_.keys()))[0] # select the most common word(s)\n",
    "        # rename label with common word(s)\n",
    "        pop_df_dep.loc[pop_df_dep[\"Department (General)\"] == str(cluster_num), \"Department (General)\"] = str_label \n",
    "\n",
    "# give unlabeled data-points the label np.nan\n",
    "pop_df_dep[\"Department (General)\"] = pop_df_dep[\"Department (General)\"].replace({\"1\":np.nan}, regex=True) \n",
    "pop_df_dep.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dcf0be-51de-4fb3-bc8f-b1199e156bd1",
   "metadata": {},
   "source": [
    "Now the labels of the data points are more interpretable. Below we can see all of the unique labels. This list of unique labels was useful when deciding which words to remove from the data, such as \"Faculty of\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec21b95-6b2a-4ed3-b89a-5568503d6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep[\"Department (General)\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f769242-6f73-4796-826d-8eb9b8edb37b",
   "metadata": {},
   "source": [
    "We can see that some of these labels need adjustments. Below, I manually alter the labels for interpretability and to further combine some groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a8ef9-0e80-4818-b35f-325088164405",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep[\"Department (General)\"] = pop_df_dep[\"Department (General)\"].replace({\"Computer Engineering\":\"Engineering\", \n",
    "                                                                   \"Educational Studies\":\"Education\",\n",
    "                                                                   \"Literacy Education\":\"Literacy\",\n",
    "                                                                   \"Enrolment Services\":\"Enrolment\",\n",
    "                                                                   \"Materials Engineering\":\"Engineering\", \n",
    "                                                                   \"Business University\":\"Sauder\",\n",
    "                                                                   \"Sociology Department\":\"Sociology\",\n",
    "                                                                   \"Economics Vancouver\":\"Economics\",\n",
    "                                                                   \"Family Practice\":\"Medicine\",\n",
    "                                                                   \"Vancouver School\":\"Economics\",\n",
    "                                                                   \"UBC Vantage\":\"Vantage College\",\n",
    "                                                                   \"Civil Engineering\":\"Engineering\",\n",
    "                                                                   \"Stewart Blusson\":\"Physics/Astronomy\",\n",
    "                                                                   \"Law Allard\":\"Law\",\n",
    "                                                                   \"Services Facilities\":\"Facility Services\",\n",
    "                                                                   \"Sauder School\":\"Sauder\",\n",
    "                                                                   \"English Language\":\"English\",\n",
    "                                                                   \"Service Centre\":\"Integrated Service Centre\",\n",
    "                                                                   \"Forestry Forest\":\"Forestry\",\n",
    "                                                                   \"Teaching Learning\":\"Teaching\",\n",
    "                                                                   \"Health Social\":\"Health & Social Development\",\n",
    "                                                                   \"Psychology Psychology\":\"Psychology\",\n",
    "                                                                   \"Human Early\":\"Early Learning\",\n",
    "                                                                   \"Obstetrics Gynaecology\":\"Obstetrics & Gynaecology\",\n",
    "                                                                   \"International Student\":\"International Student Initiative/Development\",\n",
    "                                                                   \"Earth Ocean\":\"Earth/Ocean/Atmospheric Sciences\",\n",
    "                                                                   \"Media School\": \"Journalism\",\n",
    "                                                                   \"Zoology Zoology\":\"Zoology\",\n",
    "                                                                   \"French Hispanic\":\"Language Studies\",\n",
    "                                                                   \"Astronomy Physics\":\"Physics and Astronomy\",\n",
    "                                                                   \"VicePresident Research\": \"Research & Innovation\",\n",
    "                                                                   \"Film Theatre\":\"Theatre and Film\",\n",
    "                                                                   \"Vancouver Coastal\":\"Surgery Medicine\",\n",
    "                                                                   \"Geography Geography\":\"Geography\",\n",
    "                                                                   \"Food Systems\":\"Land and Food Systems\",\n",
    "                                                                   \"Surgery Medicine\":\"Surgery\",\n",
    "                                                                   \"Special Education\":\"Counselling and Special Education\",\n",
    "                                                                   \"Economics Philosophy\": \"Philosophy\",\n",
    "                                                                   \"Digital Solutions\":\"Digital Solutions Medicine\",\n",
    "                                                                   \"Pharmacology Therapeutics\":\"Pharmacology\",\n",
    "                                                                   \"Pharmaceutical Sciences\":\"Pharmacology\", \n",
    "                                                                   \"VicePresident Academic\":\"VP Academic\",\n",
    "                                                                   \"Facilities Building\":\"Facilities Operations\",\n",
    "                                                                   \"Development Alumni\":\"Alumni\",\n",
    "                                                                   \"Medicine Neurology\":\"Neurology/Ophthalmology\",\n",
    "                                                                   \"Safety Risk\":\"Safety Services\",\n",
    "                                                                   \"Facilities Energy\":\"Energy & Water\",\n",
    "                                                                   \"Campus Community\":\"Campus & Community\",\n",
    "                                                                   \"Anesthesiology Pharmacology\": \"Anesthesiology/Pharmacology/Therapeutics\",\n",
    "                                                                   \"Population\":\"Medicine\",\n",
    "                                                                   \"Psychiatry Medicine\":\"Medicine\",\n",
    "                                                                   \"Management Dean\":\"Management\",\n",
    "                                                                   \"Biological Engineering\":\"Chemical/Biological Engineering\",\n",
    "                                                                   \"Land\":\"Land and Food\",\n",
    "                                                                   \"Cellular Physiological\":\"Cellular/Physiological\",\n",
    "                                                                   \"Medicine Psychiatry\":\"Medicine\",\n",
    "                                                                   \"Central Eastern\":\"CENES\"\n",
    "                                                                  }\n",
    "                                                                  , regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75de211-ddac-4019-94ba-d6a041c4555f",
   "metadata": {},
   "source": [
    "Below are the updated department labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8087169-4a41-4836-98b9-021557ce3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep[\"Department (General)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e298a-ee46-4405-b690-a043cd314d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_department_category(list_of_unique_deps):\n",
    "    '''a tool to help quickly change reduced department values to more intuitive ones'''\n",
    "    for department in list_of_deps:\n",
    "        print(department) # print out original department\n",
    "        is_correct_dep = input(\"Does this look right? (y/n)\") \n",
    "        if is_correct_dep == 'n':\n",
    "            # print out 10 examples of values in the non-reduced department column\n",
    "            print(pop_df_dep[pop_df_dep[\"Department (General)\"] == department][['Department']].head(10))\n",
    "            # ask for a better reduced department value\n",
    "            correct_department = input(\"Type out the correct department: \")\n",
    "            # change the department value\n",
    "            pop_df_dep[\"Department (General)\"] = pop_df_dep[\"Department (General)\"].replace(department,correct_department)\n",
    "            print(department + \" was changed to \" + correct_department)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0606aa3b-385b-45a7-9e4d-ec9c95814e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8be7af-739e-432d-85a2-202366c695d1",
   "metadata": {},
   "source": [
    "There are now cleaned, grouped departments for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80fa03-1a04-446d-bd9c-cf60fbbeb65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making nan values the same \n",
    "pop_df_dep['Department (General)'] = pop_df_dep['Department (General)'].replace('',np.nan)\n",
    "pop_df_dep['Department (General)'] = pop_df_dep['Department (General)'].replace('nan',np.nan)\n",
    "# removing unessecary column\n",
    "pop_df_dep = pop_df_dep.drop(columns = [\"Department - short\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a934271-aee1-4586-9bef-733a7ea96874",
   "metadata": {},
   "source": [
    "Now for clustering the job titles. Instead of using DBscan, I created my own grouping method as DBscan wasn't quite capturing the groups for title that I had in mind. The below code will find titles that include words such as 'Professor' or 'Admin' and then reduce the title to just that word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595f7a73-caf3-4453-9826-972f818302c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep['Title (General)'] = '' # create new column for reduced title\n",
    "pop_df_dep['Title'] = pop_df_dep['Title'].str.title() # make sure Title column is in title case\n",
    "\n",
    "def reduce_title_or(df, str_list):\n",
    "    ''' if the title contains a string in the string list, reduce the title to that string'''\n",
    "    for reduced_str in str_list:\n",
    "        df.loc[df['Title'].str.contains(reduced_str), 'Title (General)'] = reduced_str\n",
    "    return df\n",
    "\n",
    "\n",
    "pop_df_dep = reduce_title_or(pop_df_dep, ['Professor','Director','Research','Manager','Instructor','Lecturer',\n",
    "                                          'Adivsor','Librarian','Analyst','Admin','Lead',\n",
    "                                         'Coordinator','Writer','Architect','Officer'])\n",
    "\n",
    "pop_df_dep['Title (General)'] = pop_df_dep['Title (General)'].replace('',np.nan)\n",
    "pop_df_dep['Title (General)'] = pop_df_dep['Title (General)'].replace('nan',np.nan)\n",
    "pop_df_dep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc979b-3007-45fe-b5cf-9b63d7d207dd",
   "metadata": {},
   "source": [
    "We have cleaned data for title and department columns for each observation. I will also change \"nan\" values to \"Not Available\" to be more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b633b2-864e-41ee-8d7c-1e845a97b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep = pop_df_dep.replace(np.nan, \"-- Not Availible --\")\n",
    "pop_df_dep['Department'] = pop_df_dep['Department'].replace('nan',\"-- Not Availible --\")\n",
    "pop_df_dep['Title'] = pop_df_dep['Title'].replace('Nan',\"-- Not Availible --\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f0889a-834d-4754-bf5f-c223ca49a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d7cd7d-21a2-4e44-adde-32e22b179582",
   "metadata": {},
   "source": [
    "The next step will be to predict gender data for each observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d70d8e-7ebf-4249-b1f3-48da3fb32dcf",
   "metadata": {},
   "source": [
    "## Predicting Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb890d2d-199a-4b15-9356-81a0ea69f92b",
   "metadata": {},
   "source": [
    "Including gender data will allow for an interesting analysis of salary separated by gender. There is a well known pay gap between male and female employees around the world so it will be interesting to see if this gap shows up in the UBC faculty population as well. As mentioned in the introduction, requesting gender data from UBC would create the most accurate dataset. Instead, in order to practice natural language processing and data wrangling, I will attempt to predict gender values based on global gender data. Since these predictions may not be accurate, it is important to be skeptical of any hard conclusions drawn from analysis on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1e73c-9af5-4ad5-ae40-fbe8ea3bf3a4",
   "metadata": {},
   "source": [
    "Also, the only gender labels will be Female and Male which is not representative of the spectrum of genders that exist in the world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a0dde-9270-4617-b725-c460829179fc",
   "metadata": {},
   "source": [
    "### Using corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c885ba73-eeff-4cc9-8a02-e801885d0e44",
   "metadata": {},
   "source": [
    "The easiest and quickest way to estimate the gender of the UBC faculty without asking UBC for the information is probably to a corpus with names and genders. Then for each name, I find whether there are more associated girl or guy names in the corpus and the result will be the predicted gender."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae6469-77e2-4517-8e3d-642f0de87ffe",
   "metadata": {},
   "source": [
    "First, I will read in Canadian baby name data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca67b0-5cf3-4d82-af4f-5cdb5533a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in canadian data we will use to train our model\n",
    "# Data from statcan - https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=1710014701\n",
    "# Includes baby name data (name, sex at birth) for babies from 1991 to 2021\n",
    "canadian_names = pd.read_csv('data/17100147.csv')\n",
    "canadian_names['First name at birth'] = [i.split(' ')[0] for i in canadian_names['First name at birth']]\n",
    "canadian_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1be7ff-ad14-46de-9633-d3497aa4d828",
   "metadata": {},
   "source": [
    "Then, I will find the total number of baby names split by sex and name (VALUE), as well as the total number of baby names just split by name (TOTAL VALUE).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44350811-254d-4294-bee5-e0603a31cf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_totals(df):\n",
    "    '''add column with total counts across name'''\n",
    "    # Find the total count of male + female for each baby name\n",
    "    totals = df[['First name at birth','VALUE']].groupby(['First name at birth']).sum().reset_index().rename(columns = {'VALUE':'TOTAL VALUE'})\n",
    "    # Merge the total count with the rest of the baby name data\n",
    "    df = pd.merge(df, totals, on = 'First name at birth', how = 'left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f178b-c135-4df9-9de2-b6812b512b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by baby name and sum frequency counts over the years, remove unnecessary features\n",
    "canadian_names = canadian_names.query(\"Indicator == 'Frequency'\")[['Sex at birth', 'First name at birth','VALUE']].groupby(['Sex at birth', 'First name at birth']).sum().reset_index()\n",
    "# Find the total count of male + female for each baby name\n",
    "canadian_names = find_totals(canadian_names)\n",
    "canadian_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba93565-11cc-4263-ba8a-e501975a5f6d",
   "metadata": {},
   "source": [
    "Now, I will complete the same process with an american baby name dataset, making sure the american data is in the same format as the Canadian data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f0c6ea-6049-4487-b788-6d995d3509f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in extra data for american names and clean it up so that it can be merged with other training data\n",
    "# https://www.kaggle.com/datasets/kaggle/us-baby-names/code\n",
    "american_names = pd.read_csv(\"data/NationalNames.csv\")\n",
    "# If there are multiple names, just keep the first one\n",
    "american_names['Name'] = [i.split(' ')[0] for i in american_names['Name']]\n",
    "# Rename columns to match Canadian data\n",
    "american_names = american_names.rename(columns = {'Name':'First name at birth', 'Gender':'Sex at birth','Count':'VALUE'})\n",
    "# Relabel sex data to match Canadian data\n",
    "american_names['Sex at birth'] = american_names['Sex at birth'].replace({'F':'Female','M':'Male'})\n",
    "\n",
    "# Find counts for each name/gender combo over the years\n",
    "american_names = american_names[['Sex at birth', 'First name at birth','VALUE']].groupby(['Sex at birth', 'First name at birth']).sum().reset_index()\n",
    "# Find total for each name across gender\n",
    "american_names = find_totals(american_names)\n",
    "american_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e90c3c-321b-4faa-ab4e-46b713c574fe",
   "metadata": {},
   "source": [
    "The next step is to combine American and Candian data into one large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8764bf-c9bf-462e-bce9-1e3011f65473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine american and canadian data\n",
    "combined_names = pd.concat([canadian_names,american_names])\n",
    "combined_names = combined_names.dropna()\n",
    "# make sure that the names are in Title Case to ensure consistency.\n",
    "combined_names['First name at birth'] = combined_names['First name at birth'].str.title()\n",
    "# sum up the value and total value counts for American and Canadian data\n",
    "combined_names = combined_names[['Sex at birth', 'First name at birth','VALUE','TOTAL VALUE']].groupby(['Sex at birth', 'First name at birth']).sum().reset_index()\n",
    "combined_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb811af-d6f1-4236-bccb-d4b1428feb29",
   "metadata": {},
   "source": [
    "Now, for each name I will find which sex has the highest percentage of observations (`Accuracy`) and only keep that sex in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd99e2f5-f49b-47be-af6b-8e35536589d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that contains the percentage of counts that are [fem/male] for the given baby name\n",
    "combined_names['Accuracy'] = round(combined_names['VALUE']/combined_names['TOTAL VALUE'],2)\n",
    "# keep row with the sex that has the highest accuracy\n",
    "combined_names = combined_names.sort_values('Accuracy', ascending=False).drop_duplicates('First name at birth').reset_index()\n",
    "# drop useless columns\n",
    "combined_names = combined_names.drop(columns = ['VALUE', 'TOTAL VALUE'])\n",
    "# sort values by accuracy\n",
    "combined_names.sort_values(by = 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ac7392-1ddc-40c8-8219-e1fae463ed0d",
   "metadata": {},
   "source": [
    "Above we can see that names with accuracy close to 0.5 are names that are often used for males and females, while names with accuracy 1.0 are almost always used for just one sex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82869ff-a736-41ae-ba0a-6913a687b20b",
   "metadata": {},
   "source": [
    "After some investigation, I noticed that there were quite a few names of Indian origin in the UBC faculty dataset that were not included in our name corpus. Therefore, I will add names with Indian origin to the name corpus. This step wasn't integrated into the above process because this Indian name dataset does not have a 'counts' or 'value' column to determine sex `Accuracy`. Therefore, the accuracy column for this data will be filled with a fairly arbitrary value of 0.85."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f9e709-4a1c-4ebe-92c0-3ca0ed70f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in extra data for indian names and clean it up so that it can be merged with other training data\n",
    "# https://www.kaggle.com/datasets/ananysharma/indian-names-dataset\n",
    "f_indian_names = pd.read_csv('data/Indian-Female-Names.csv')\n",
    "m_indian_names = pd.read_csv('data/Indian-Male-Names.csv')\n",
    "# Combine female and male names\n",
    "indian_names = pd.concat([f_indian_names,m_indian_names])\n",
    "# rename columns to match name corpus\n",
    "indian_names = indian_names.rename(columns = {'name':'First name at birth', 'gender':'Sex at birth'})\n",
    "# relabel sex data to match name corpus\n",
    "indian_names['Sex at birth'] = indian_names['Sex at birth'].replace({'f':'Female','m':'Male'})\n",
    "# make sure names are in title case\n",
    "indian_names['First name at birth'] = indian_names['First name at birth'].str.title()\n",
    "# If there are multiple names, just keep the first one\n",
    "indian_names['First name at birth'] = [str(i).split(' ')[0] for i in indian_names['First name at birth']]\n",
    "# drop unnecessary columns\n",
    "indian_names = indian_names.drop(columns = ['race'])\n",
    "# Apply arbitrary accuracy value\n",
    "indian_names['Accuracy'] = 0.85\n",
    "indian_names.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0f9d4f-6534-4287-996d-056e73f88083",
   "metadata": {},
   "source": [
    "Now I will combine the Indian name data with the previous name dataset to create a more complete name corpus. I will only add names from the Indian name dataset that don't already exist in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ad381-64da-4994-8307-4fac4c7627f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_corpus = pd.concat([combined_names,indian_names]).drop_duplicates(subset = ['First name at birth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e107d6d-fa41-46d7-a899-ad00936685e3",
   "metadata": {},
   "source": [
    "Next, I will determine what the percentage of the names in the UBC dataset is that we can match to a sex using our name corpus. I will also create a dataset with UBC faculty members that still need a sex prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd51add-7e14-4c31-ada2-f10b1a04d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the names and gender dataset onto the UBC dataset to see if there are exact name matches\n",
    "pop_df_dep['First Name - drop'] = [str(i).split(' ')[0] for i in pop_df_dep['First Name']]\n",
    "pop_df_predicted = pd.merge(pop_df_dep, name_corpus, left_on = ['First Name - drop'], right_on = ['First name at birth'], how = 'left')\n",
    "pop_df_predicted = pop_df_predicted.drop(columns = ['First Name - drop'])\n",
    "# Create dataset for exact name matches\n",
    "pop_df_predictions = pop_df_predicted[pop_df_predicted['Sex at birth'].notnull()]\n",
    "# Create dataset where there was no exact match and sex still needs to be predicted\n",
    "pop_df_needs_predictions = pop_df_predicted[~pop_df_predicted['Sex at birth'].notnull()]\n",
    "# Find\n",
    "len(pop_df_predictions)/len(pop_df_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbaf41-2fd7-4db5-9a01-2a7c30856af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_dep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40598b77-db44-4069-bff7-9fd2320d5659",
   "metadata": {},
   "source": [
    "I was able to match 92% of the names in the UBC salary dataset with my corpus! However, there are still quite a few names that need gender predictions. For this task, I will use the nltk package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c8991-8449-4bf7-97ad-f588def82a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_needs_predictions['First Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fee3fa-bbab-47d2-9f1e-df1547086a0c",
   "metadata": {},
   "source": [
    "### Using nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9be601-e265-4bd8-b231-895a03d22b81",
   "metadata": {},
   "source": [
    "To predict the gender for the rest of the names, I will use natural language processing, specifically the nltk package. I will also use the name corpus I have put together as the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7b0bf-8267-49c4-b6ac-6e3790b9fb4b",
   "metadata": {},
   "source": [
    "The first step is feature engineering. The features I will use are the last, two last, three last, four last, and five last letters in the name. This can capture patterns such as the four last letters 'etta' more often being used for girls names than boys names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69209983-7168-4834-a99e-db676deaaecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return features of a name to be fed into our model\n",
    "def gender_features(word):\n",
    "    word = word.lower()\n",
    "    return {'last_5_letters': word[-5:], 'last_two_letters': word[-2:],\n",
    "            'last_letter': word[-1:], 'last_3_letters': word[-3:], 'last_4_letters': word[-4:], 'name': word}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca005d1f-ae12-4fa0-a741-3087594183c9",
   "metadata": {},
   "source": [
    "In order to evaluate how well this gender classifier model works, I will shuffle the name corpus, apply feature engineering to the dataset, and then split it into training data and testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3318c57-c00d-4575-8a4c-a7c422d2d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle our data\n",
    "name_corpus = name_corpus.sample(frac=1,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57afd38-6da1-4572-a269-edaffdbbf18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect features for each name in our data\n",
    "featuresets = [(gender_features(row['First name at birth']), row['Sex at birth']) for (index, row) in name_corpus.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604b64c6-e537-40ae-8d88-39a732a90b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the shuffled data into train and test sets\n",
    "train_set, test_set = featuresets[3157:], featuresets[:3157]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7654b2-7385-4042-a945-4c316886fe42",
   "metadata": {},
   "source": [
    "Next, I will train the classifier on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd99f4-4856-40f2-a1e0-10c1878bc466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train our classifier with the train set\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b2919-cbd5-4b5e-9ab5-a6fcb91004f8",
   "metadata": {},
   "source": [
    "Now, I can score the model with the test set to see how accurate the classifier is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f1637-1bd0-41e6-bb62-1b0fda1a1b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score our classifier with the test set\n",
    "accuracy = round(nltk.classify.accuracy(classifier, test_set),2)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9ce10-3b91-46eb-8c03-0fde5a3d4f21",
   "metadata": {},
   "source": [
    "85 percent accuracy is pretty good. However, the accuracy on the actual data is likely lower that 85 since the actual data contains more unique, unusual names that were not found in our name corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced43be-f314-42ef-8798-a7796c83d4be",
   "metadata": {},
   "source": [
    "Below we can check which features are most informative for our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850bffcc-ebc5-4860-ac64-d5be498360a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out most informative features for the classifier\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476cc078-97ae-44cd-8802-47c5e1c94066",
   "metadata": {},
   "source": [
    "Some of the more informative features for females are names ending with 'isha','etta', and 'ena'. One of the more informative features for males are names ending with 'rick'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46beb4a-fdc5-449c-91f2-aae83d0fcb25",
   "metadata": {},
   "source": [
    "Finally, I can predict the gender of names in the UBC dataset that still do not have an assigned gender. The accuracy for these predictions will be the value provided by the classifiers prob_classify_many function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541de1c-6bb3-4db5-be2f-75eaa560f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect features for each name in our UBC data that still needs a sex assigned\n",
    "pop_df_needs_predictions.loc[:,'First Name'] = pop_df_needs_predictions['First Name'].astype(str)\n",
    "pop_testset = [(gender_features(row['First Name'])) for (index, row) in pop_df_needs_predictions.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c1a17-e352-41f0-92b1-e0c0b0e7eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and note the classifier accuracy\n",
    "pop_df_needs_predictions.loc[:,'Sex at birth'] = classifier.classify_many(pop_testset)\n",
    "# For accuracy I am using the predict proba score given by the classifier\n",
    "pop_df_needs_predictions.loc[:,'Accuracy'] = [max(i.prob('Male'),i.prob('Female')) for i in classifier.prob_classify_many(pop_testset)]\n",
    "pop_df_needs_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0070532c-ef42-4db1-b82b-901b540f69ae",
   "metadata": {},
   "source": [
    "### Clean-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f366c645-28f6-4979-969b-e007970a3c96",
   "metadata": {},
   "source": [
    "Now that every UBC faculty member has an assigned gender, I can concat the the corpus-prediction dataset and the nltk-prediction dataset together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a763348e-7e08-431d-9bf6-d055b4a7ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all the data together\n",
    "pop_df_complete = pd.concat([pop_df_predictions, pop_df_needs_predictions]).drop(columns = ['First name at birth','index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75811c93-0aa1-442e-a690-90ed44ed63eb",
   "metadata": {},
   "source": [
    "Below I will create a histogram of all of the accuracies to get a sense of how confident I can be in the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f5731-7f8f-4d29-adbe-4e40b623ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of recorded accuracies for each predicted gender\n",
    "pop_df_complete['Accuracy'].plot.hist(bins=50)\n",
    "plt.title('Histogram of Predicted Gender Accuracies')\n",
    "plt.xlabel('Predicted Gender Accuracies')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c402305-1d89-4840-9b97-e6f06fe4e07a",
   "metadata": {},
   "source": [
    "It's great to see that most of the recorded accuracies are very high. It's also important to remember that these estimated accuracies may not accurately represent how correct the predictions are. One reason for this is that for the nltk classifier, the training data was not very representative of the data that needed predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a89a3-ba95-4574-89a7-c2eae31c64eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_complete[pop_df_complete['Accuracy'] < 0.8].shape[0]/pop_df_complete.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b173dc3e-3024-45bc-aa8d-e6d2a89b7a7e",
   "metadata": {},
   "source": [
    "In order to ensure that conclusions gathered from this data are more accurate, I will replace the estimated gender with null values for observations with accuracies under 80%. This will only affect around 4% of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066da672-110e-4a78-9e40-74cf9b86038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_complete.loc[pop_df_complete['Accuracy'] < 0.8,'Sex at birth'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2f370a-09ed-460e-8e58-acbc6bc81bf6",
   "metadata": {},
   "source": [
    "Below I will manually correct a few  miss-classifications that I noticed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a31e39-b0ac-4b80-962b-b6610ebc3bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df_complete.loc[(pop_df_complete['First Name'] == \"Lakshmi\") & (pop_df_complete['Last Name'] == \"Yatham\"),'Sex at birth'] = \"Male\"\n",
    "pop_df_complete.loc[(pop_df_complete['First Name'] == \"Santa\") & (pop_df_complete['Last Name'] == \"Ono\"),'Sex at birth'] = \"Male\"\n",
    "pop_df_complete.loc[(pop_df_complete['First Name'] == \"Ali\") & (pop_df_complete['Last Name'] == \"Lazrak\"),'Sex at birth'] = \"Male\"\n",
    "pop_df_complete.loc[(pop_df_complete['First Name'] == \"Jan\") & (pop_df_complete['Last Name'] == \"Bena\"),'Sex at birth'] = \"Female\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df32672-f236-49cd-875f-ce805df316fb",
   "metadata": {},
   "source": [
    "Finally, I will export the data to be used to create a Tableau dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd2b7f1-0712-407a-88ac-8c238a1146be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataset\n",
    "pop_df_complete.to_excel('/Users/jadebouchard/Desktop/UBC Salaries/ubc_salary_deparment_gender_all.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526d539-aafc-4f83-847e-a8affc8bed14",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2e4377-385f-4874-b329-781e01d5549a",
   "metadata": {},
   "source": [
    "Below is a Tableau dashboard showing a visual representation of the data.\n",
    "The dashboard can also be accessed through this [link](https://public.tableau.com/views/UBCSalary/Dashboard1?:language=en-US&:display_count=n&:origin=viz_share_link)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bc171-2735-43f9-a4ef-a4cbf708fcc7",
   "metadata": {},
   "source": [
    "- The top left graph is a histogram of salary, stacked by gender.\n",
    "- The top right graph is a bar chart of median salaries, split by job title and gender\n",
    "- The bottom left graph is a circle bar chart of median salaries split by gender and department\n",
    "- The bottom right graph is a side-by-side box plot of salaries, split by department\n",
    "\n",
    "You can hover over a portion of a plot to get exact values. In addition, you can filter by title and department on the right side of the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eef732-8274-471a-8455-16798663ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<div class='tableauPlaceholder' id='viz1700094097675' style='position: relative'><noscript><a href='#'><img alt='Dashboard 1 ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;UB&#47;UBCSalary&#47;Dashboard1&#47;1_rss.png' style='border: none' /></a></noscript><object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='' /><param name='name' value='UBCSalary&#47;Dashboard1' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;UB&#47;UBCSalary&#47;Dashboard1&#47;1.png' /> <param name='animate_transition' value='yes' /><param name='display_static_image' value='yes' /><param name='display_spinner' value='yes' /><param name='display_overlay' value='yes' /><param name='display_count' value='yes' /><param name='language' value='en-US' /></object></div>                <script type='text/javascript'>                    var divElement = document.getElementById('viz1700094097675');                    var vizElement = divElement.getElementsByTagName('object')[0];                    if ( divElement.offsetWidth > 800 ) { vizElement.style.width='1120px';vizElement.style.minHeight='587px';vizElement.style.maxHeight='687px';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else if ( divElement.offsetWidth > 500 ) { vizElement.style.width='1120px';vizElement.style.minHeight='587px';vizElement.style.maxHeight='687px';vizElement.style.height=(divElement.offsetWidth*0.75)+'px';} else { vizElement.style.width='100%';vizElement.style.height='1377px';}                     var scriptElement = document.createElement('script');                    scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);                </script>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b30fcf-9490-4609-8649-824fb399d21e",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac62f55-eee1-4b94-b39b-d887cecc8aa1",
   "metadata": {},
   "source": [
    "In summary, I accomplished my main objective of gaining experience in wrangling data and machine learning. In addition, I was able to visualize the data using an interactive Tableau dashboard. This method of presenting the data seems to be much more user-friendly than the PDF that the University of British Columbia provides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501905bc-b6ac-48d1-b4ba-30ecf40ec201",
   "metadata": {},
   "source": [
    "**Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a439a-ff91-4ab0-aab0-3fe62f9bf8f2",
   "metadata": {},
   "source": [
    "There are many potential conclusions to be derived from the data presented here. This project stops short at the analysis of the data as the primary objective is to wrangle and visualize the data, which has been accomplished. For future work, an analysis on the statistical significance of salary disparity between genders, titles, and departments would be interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a415c7-1990-481c-910b-5d14fb43ef4b",
   "metadata": {},
   "source": [
    "If you are interested in seeing demonstrations of my analysis skills, please check out the following projects on GitHub:\n",
    "</br>[Forest Fire Impact Prediction Using Linear Regression](https://github.com/jjadeb/Stat_301_Project)\n",
    "</br>[Impact of Internet Access on Final Grade Using the T-Test](https://github.com/jjadeb/stat-201-project)\n",
    "</br>[Analysis of Celebrity Age of Death using Stratified Sampling](https://github.com/jjadeb/STAT334-Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a399d-1409-40d0-845c-79c17f6bb6ce",
   "metadata": {},
   "source": [
    "**Data Limitations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd214c-c2cd-48e6-91b4-fd30ad165e1f",
   "metadata": {},
   "source": [
    "Any conclusions drawn from the data must take into account the inaccuracies of the department, job title, and gender information. This is partly due to the error involved in clustering and natural language classifiers. In addition, we saw there were many missing data-points for department and title information, therefore the data in the visualization may not accurately represent the entirety of the UBC faculty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f169abf-3c5b-4251-9c24-242dda3fc7e1",
   "metadata": {},
   "source": [
    "**Final Note**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38cb63-f958-4573-8b28-23ce970e8dcd",
   "metadata": {},
   "source": [
    "Overall, this project not only advanced my skills in data manipulation and visualization but also laid the groundwork for future in-depth analyses. I also enhanced my understanding around how data collection and cleaning methods can lead to data limitations, impacting the ability to make meaningful conclusions during analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
